---
title: 爬虫优化之道
author: Payne
tags: ["爬虫", "Crawler", "Web Spider", "数据采集"]
categories:
- ["爬虫", "Crawler", "Web Spider", "数据采集"]
date: 2021-05-26 09:05:26
---
## 网络爬虫

### 网络爬虫的定义

爬虫又称为网络蜘蛛、网页追逐者。是一种按照一定的规则，自动地抓取万维网信息的程序或脚本

同时还有很多种说法,但我个人认为最通俗的理解就是，模拟用户访问的程序或脚本。

<!--more-->

### 网络爬虫实现的核心步骤

无论多么复杂的爬虫都离不开以下核心的四步，当然极少数特例除外。

- 确定数据URL

- 发送请求,获取响应

- 解析响应，获取数据

- 数据持久化

## 网络爬虫优化

无论是何种方向，我们都希望以更少的代价获取更大的收益，相信优化这一个话题一直是大家所探讨的。

决定网络爬虫性能的指标有很多，在不考虑特殊情况及阀值情况下

网络请求更快，解析效率更快，数据持久化更快等，那么爬虫会更快，这个是必然的

那么网络爬虫该如何优化，且听我从以下几个方面进行分析。

1. 分布式爬虫：更多的worker
2. 减少重复或无效的网络请求、减少或分割繁琐的请求流程
3. 网络优化
4. 解析优化
5. 数据持久化

### 爬虫优化第一式-分布式爬虫

在网络爬虫的世界中，我们爬虫工程师开发的爬虫一般都是聚焦爬虫，而一个网站的数据量假设是个常量。那么爬虫的任务量也是个定值。那么更多的爬虫，一定是比单机单任务爬虫更快的。

> 一般来说我们接触网站的数据增长量，还没有达到那种成几何倍数增长的情况。在这里只为论述大多情况下。特殊情况下例外

分布式爬虫概念，在此便不再过多赘述，感兴趣的朋友可以自行搜索。

实现分布式爬虫的核心理念就是任务共有化统一调度。在这里爬虫领域，我们可以简单的理解为URL或URN的管理。只要管理好了URL或URN，分布式爬虫相信你实现起来也并不困难。分布式爬虫基础架构图如下所示

![](https://tva1.sinaimg.cn/large/008i3skNgy1gquzrwsspdj30r50do0sr.jpg)

**分布式爬虫优化之一，氪金：**

只要机器够多，配置够高，集群够强大。那么日入过亿so easy。

**分布式爬虫优化之二：部署优化**

在以上的基础上，对于资源利用并不能够达到一个很完美的情况。如果有上百台机器，一个一个去启动爬虫没开完，爬虫工程师们就累死在了半路上。

**部署优化之一:单机批量运行**

> 在一台机器机器中是允许开启多个爬虫！！！

使用shell脚本，进行批量运行。

使用subprocess，进行批量运行。

**部署优化之二：虚拟容器**

在以上的基础上，我还建议你使用 docker，Kubernetes进行多机器分布式爬虫的部署。只需要短短几个命令即可部署到服务器。

这样就可以实现快捷部署

### 爬虫优化第二式：爬取策略

减少重复或无效的网络请求、减少或分割繁琐的请求流程。

首先我们来看个较经典的页面结构图，大部分页面都是一种B*树 或者图的数据结构。

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqv1hqdepcj31400u04qr.jpg)

<div style="text-align: center;">首页简称Index，列表页简称List， 详情页简称detail</div>



网页结构的不同采用不同遍历方式也不同，采用先深度后广度将是最快的“路径”。

如果detail可以一直获取到下一页

直接从起始页到最后一页。时间复杂度为O(N),N为总页数

如果只能列表页才能获取详情页

翻页获取下一页，可从先遍历List页后遍历获取详情页。时间复杂度为O(MN), M为列表页数，N为详情页数

如果是图，建议转化为树形结构进行考虑

> 小技巧：
>
> 如何制定抓取策略？
>
> 建议自底向上的方式，先考虑详情页是否可以直达，后考虑列表页从而间接获取详情页

#### 进阶

如果是分布式爬虫，那么我们可以使用生产者-消费者模型的概念。ListCrwaler获取详情url，存入URL-Pool中

如下图所示

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqv21zh059j30f70asglk.jpg)

> 存入到URL-pool中建议使用Set进行URL去重。当URL过大的时候我们可以剔除公共部分，仅保存Id。
>
> 若数据量极大，可使用**BloomFilter算法**

### 爬虫优化第三式: 请求优化

#### 异常处理之超时

当连接超过某个阀值，可判定此次请求失败。个人偏爱timeout 为60s

#### 提高并发量

合适的并发量可以将资源使用到极致，合适的并发量可以从按照实际情况调。

#### IP

### 爬虫优化第四式：网络优化

#### 网络IO

**网络带宽**

#### DNS解析

**域名系统**（[英文](https://baike.baidu.com/item/英文)：**D**omain **N**ame **S**ystem，[缩写](https://baike.baidu.com/item/缩写)：**DNS**）是[互联网](https://baike.baidu.com/item/互联网)的一项服务。它作为将[域名](https://baike.baidu.com/item/域名)和[IP地址](https://baike.baidu.com/item/IP地址)相互[映射](https://baike.baidu.com/item/映射)的一个[分布式数据库](https://baike.baidu.com/item/分布式数据库)，能够使人更方便地访问网页。

简易的访问步骤到获取到呈现页面

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqv2nmieu3j30f90c1wec.jpg)

当大规模抓取每次都要做DNS解析时，浪费的时间是非常大的。所以如果能在本地做DNS缓存，每次系统都读本地DNS的话，这个时间消耗大大降低。

**实现DNS缓存的常见几种方法**

最简单的方法就是直接修改/etc/hosts文件，在文件里直接添加IP和域名，例如这样

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqv30rtefqj30mt0bbjrk.jpg)

![](https://tva1.sinaimg.cn/large/008i3skNgy1gqv3074tn5j30s60apmx7.jpg)

第二种方式：使用DNS缓存工具，例如DNSmasq

### 爬虫优化第五式：解析优化

智能解析算法

### 爬虫优化第六式：数据持久化优化

一次插入多条

异步插入多条

### 爬虫优化第七式：多数据源

单一的数据源难免由于并发量过大，给目标网站造成DDos攻击。

### 总结

分别从分布式爬虫，抓取策略、请求优化、网络优化、解析优化、与多数据源方面进行考虑。希望对你能够有所启发

最后在开启超大规模的爬虫建议计算对方的带宽压力，不要抓取太过分了。抓取归抓取，但不要影响对方网站正常运营。



<div style="text-align: center;">以上便是鄙人所知所用的爬虫方法论，希望能帮助到你。</div>